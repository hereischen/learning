virtio: Towards a De-Facto Standard For Virtual I/O Devices

abstract

Linux内核目前支持至少8种虚拟化系统：Xen, KVM, VMware’s VMI, IBM’s System p, IBM’s System z, User Mode Linux, lguest and IBM’s legacy iSeries.看上去很可能会有更多的这种系统出现，直到最近以上各种系统都有了自己的分段，网络，控制器和其他驱动并有各自不同的特性与优化。

本文意在介绍virtio，一个系列高效，良好维护的linux驱动，可以通过一个中间层被改造成各种不同的管理程序实现。这包括为不同驱动提供一个简单的可扩展的机制。我们也提供一个明显的环缓冲传输实现叫做vring，它被用于KVM和lguest。这给所有新的hypervisor提供了一个阻力最小的路径：支持高效的传输机制会立即减少需要被完成的工作。最后我们会给出一个呈现vring 传输和把设备设置成PCI设备的的实践，这意味着客操作系统仅需要一个新的PCI驱动，同时hypervisor只需要加入vring支持到实现的虚拟的设备（目前只有KVM这样做）。

这篇文章将会描述集成在linux的virtio API 层，vring实现，在PCI驱动种的实施方案。我们将会以一些初期集成这项I/O机制到linux内核的工作为结尾。

1 Introduction

linux内核被用于大量的平台上，正式的内核包含24分离的结构目录，八百四十万行中二百万行是关于结构的代码。这些结构支持各种不同平台变种。不幸的是我们发现只有一种平台删除了树结构，而新的硬件像杂草一样生长。当每天有10000行代码修改，内核有至少一件事你可以想到。

当我们把linux看作一个虚拟化的客机，我们应该感到庆幸IBM’s System p, System z and legacy iSeries都支持。用户模式linux很早就被加入，可以把linux作为一个用户空间进程运行在Power, IA64 and 32 and 64 bit x86 机器上。在过去几年，X86构架被证明收获颇丰，有Xen， VMI， KVM。最后，还有我们的lguest，一个悄然加入的适用于开发教学玩具hyperviosr。

这八种平台都有自己模块，网络，控制台的驱动，甚至帧缓冲，USB控制器，主机文件系统和虚拟厨房沉控制器。其中一些也从某些显著的方面进行了优化，互相重叠但又有一些不同的特质。重要的是，没有一个没有一个特别完满他们的驱动，或者维护他们。

这个问题于KVM息息相关，并从2006年还没有准虚拟化设备模式时，就起引起了广泛关注。 模拟设备性能的局限已经很清楚，
very-Xen-centric模型跟其他正在开发的模型也是一样。我们相信是可以开发一个一般性的高效的能在多个hypyervisor和平台虚拟I/O机制，同时避免Xen设备设置的系统。

2. Virtio： The Three Goals
我们对驱动统一最开始的目标是：所有的工作都在linux内核内，所以不需要借助其他方面的帮助。如果boutique virtual I/O mechanisms开发者熟悉linux，这就能帮助他好的对应linux API与他们的ABI。但是如果这样是低效的，我们有更大的野心。

经验证明，精致的传输机制不仅应对一个hypervisor，一种构架更是一对一个具体类型的设备。所以下一步是企图为一般发布和应用缓冲提供一个统一的ABI。我们的virtio-ang实现有意的不去重新变革。开发者将会喜欢这些代码。

最后，我们提供两套ABI实现：用virtio—ring结构和虚拟I/O设备的linux api。这些是了虚拟I/O的最终部分：设备检测和配置。重要的是，他们展示了用linux虚拟API来提供其后兼容的功能交流是多么简单，所以今后linux驱动能被任何主机实现检测和使用。

明确的区分驱动，传输和配置另一种对实现的想法。例如，你不能在一个新的hypervisor上用Xen‘s linux网络驱动，除非你支持Xen-Bus探测和配置系统。

3. virtio： A LINUX-INTERNAL ABSTRACION API

如果我们向减少重复的虚拟设备驱动，我们一个好的抽象方式使驱动可以共享代码。一个方法是提供一些列虚拟驱动可用的功能助手。更具野心的方案是用通用驱动，和一个执行结构：一系列操作函数指针来处理通用驱动与其他传输实现对接。它的任务是创建一个简单的，接近最优高效的传输，并且能与现有传输很好整合的传输抽象给所有虚拟设备。

目前的结果（结成进2.6.24）是virtio驱动登记自己去处理一个32bit设备类型，限制于一个特定的32bit供应商。这个驱动的探测在一个合适的virtio设备被发现使被调用： struct virtio_device伴随一个virtio_config-ops指针被传进来。驱动于用这个指针来解开设备设置。

配置操作可会议分为四部分，读写特性信息，读西配置空间，读取状态信息和设备重设置。设备寻找于想要使用的特征相对应的指定设备类型特性信息。例如VIRTIO_NET_F_CSUM 特征信息表明一个网络设备是否支持校验和卸载。特征信息明确的被确认：主机直到什么特征信息被客机确认，和那些特性驱动知悉。第二部分是配置空间，这是一个有关虚拟设备的设备星系的结构。它可以被客机读写。例如网络设备VIRTIO_NET_F_MAC特性信息，表明这个主机想要设备有个特定MAC地址，并其配置空间有这些信息。

这个机制使我们有空间增加新特性，对主机来说增加新特性到设备只需要一个特性信息码和确认的配置空间，

有很多层哦呵做来设置读取一个客机用来表明设备探测状态的8bit设备状态词。当VIRTIO_CONFIG_S_DRIVER_OK被设置，它允许客机驱动有有完全的特性探测。这时，主机直到什么特性客机知道并想使用。

最后，重置操作来重置设备，和他的配置与状态信息。这对遇到已经初始化过的，要被再次删除添加的模块化的驱动是必须的。这样也能避免当一个驱动关闭时，从一个设备上除去缓存的问题：当重置缓存后可以确保设备不会改写他们。也可以被用来尝试恢复客机的驱动。

3.1Virtqueues: A Transport Abstraction

我们的API配置很很重要，但是api关键性能部分是I/O机制。我们的抽象化方式是virtqueue，配置操作有一个find_vq，它会根据virtio设备和索引返回提前充满数据的结构队列。有些设备比如virtio 模块设备只有一个队列，但是想像网络，控制台设备有一个输入队列，一个输出队列。

一个virtqueue是一个简单对客机提出对主机需求的缓冲队列。每个缓存是一个包括可读可写的分散聚合数组：数据的结构跟设备类型有关。virtioqueue操作结构如下：
struct virtqueue_ops {
int (*add_buf)(struct virtqueue *vq,
struct scatterlist sg[],
unsigned int out_num,
unsigned int in_num,
void *data);
void (*kick)(struct virtqueue *vq);
void *(*get_buf)(struct virtqueue *vq,
unsigned int *len);
void (*disable_cb)(struct virtqueue *vq);
bool (*enable_cb)(struct virtqueue *vq);
};
对add_buff的调用被用来添加新的缓存队列，数据变量是由驱动在缓存被利用后提供的非空序列。调用kick，可以在缓存被添加时通知其他部分，多个缓存可以在一个kick被配量添加。这很重要，因为同志通常导致大量客机退出状态。

get——buff获取一个用过的缓存：被其他部分返回的长度已经被写入的缓存。它返回一个cookie来处理add——buff或者null：不需要的缓存。

disable——cb是一个当缓存被使用是客机不需要提示：这等于禁止设备的打断。设备记录一个回调函数给virtioqueue当它被初始化。virtioqueue回调也许在启动一个服务线程前禁止特性回调。在这之后并不确定一个回调函数回被调用，但是这会需要大量同步尤其在SMP系统中。实际上，这是一个为了减少不需要的于主机和VM的交互优化。

enable——cb于disable——cb相反，通常一个驱动会在处理完所有队列里的代处理缓存后重新启动回调。在一些virtio传输中会有资源竞争：缓存会被get——bull 和enable——cb利用，或者没有回调函数被调用的时候。电平触发中断实现没有这个问题，但是对那些有这些问题的，当回调被禁止时，enable——cb回返回错误来说明更多工作出现了。

以上这些调用对很多linux情景都是可用的，并且由使用这来确定他们没有被同时调用。只有一个例外是disable——cb，它通常被回调调用，并且用来禁止回调，但是它不可靠，所以可以在任何时间发生。


4 VIRTIO_RING: A TRANSPORT IMPLEMENTATION FOR VIRTIO
机关我们认为任何优化过的传输都有相似的特性，linux virtio/ virtioqueue API是基于我们特有的传输实现，叫做viurtio——ring。

在开发virtio前，lguest已经有了一个虚拟I/O系统：一个通用，N-way I/O 机制，被使用在基于Xen的客机内联网。但是系统的复杂性来自它的广播N-way属性，它看起来只在一些客机LAN被需要。一个有趣的特性是，如果舍弃它能使我们有个更简单的涉及ringbuffers的方案，这正是告诉I/O的标准方案。经过一些开发周期，virtio——ring方案已经使用在lguest和KVM。

virtio——ring有三个组成部分：一个客机将长度和地址联系起来的描述符数组，一个可用的可以表明哪些描述符可用的ring，一个已经使用的ring，主机表明哪些描述符链已经被使用。ring的大小是可变的，但是必须是2次幂。

struct vring_desc
{
__u64 addr;
__u32 len;
__u16 flags;
__u16 next;
};
每个描述符包括缓存的客机物理地址，及其长度，一个可选的作为链接的 ‘next’缓存，和两个flag：一个用来表明下一个field是否有效，一个控制缓存是否只读或者只写。这允许一个串联的缓存包含可读和可写的项目，这对实现于一个模块设备很有用。一般，可读的缓存，优先与可写的缓存。

使用在32bit系统中使用64bit地址是一个妥协：它在旧的平台上实现了一个统一的32bit的格式。所有结构都选择避免避免填充除了一些最保守的机构。但是我们停止了段定义一个特定的endian格式L客机假定他的自然字节顺序。
struct vring_avail
{
__u16 flags;
__u16 idx;
__u16 ring[NUM];
};
一个可用的ring包括一个自由运行的索引，一个打断抑制的flag，一个包含描述符列表索引的数组。把描述符从可有的ring中分离，是因为virtioqueque的异步特性：一个可用的ring可能在快速服务的描述符轮询很多此，同时一直等待慢描述符的结束。这对实现模块设备十分有用，同样对零拷贝网络很有用。

struct vring_used_elem
{
__u32 id;
__u32 len;
};
struct vring_used
{
__u16 flags;
__u16 idx;
struct vring_used_elem ring[];
};

已经使用的ring与可用的rong相似。但是当描述符链被使用时才被主机写入。注意这里有填充，例如放置这个结构在一个与可用的ring与描述符数组分离的page。这很好的提供缓存行为并确保各方只需要一个写入到virtioqueue结构的一部分。

vring——used 和vring——avail flag，他们现在被用来抑制推送消息。例如一个正在被使用的flag，被主机告诉客机没有kick时没有必要添加缓冲，因为kcik需要 vmexit，这是一个重要的优化，kvm实现使用可这种方式，用一个计时器来控制网络传输退出迁移。相同的 avail flag被客机网络驱动使用用来直呼进一步的打断是不需要的。

最后，我们没有给客机感知暂停或恢复的基础设施，我们也不需要这些，因为我们和少发布自己的缓冲。挂起和恢复对kvm的主机的实现只有微不足道的好处。

4.1 A Note on Zero-Copy And Religion of Page Flipping

当时设计高效的I/O是，我们必须注意两件事：每个操作需要的推送消息数，被访问是cache-cold的数据量。前者被virtio——ring打断抑制flga很好的处理着。对cache-cold数据的处理需要进一步讨论。

在kvm和lguest的模式中，客机内存作为主机的进程虚拟内存空间的一部分，对主机os，那个进程是一个客机。因此从客机到主机I/O应该跟其他主机的I/O一样快，只有一些在主客机之间额外的字符转换的消耗。这就是为什么virtio在目标的I/O可以被可以访问内存前提下发布缓冲。

Xen没有这样自然的访问模式：没有这样一个主机需要访问客机的内存，所有的个体都是对等的。这等于kvm和lguest下的内客机交流，为了实现客机间的 zreo-copy，客机间对应缓冲时必要的。

需要拷贝的cache-cold数据量主导着拷贝时间。如果一个客机或主机遇到大量的数据，拷贝时间会被高度分摊。page mapping的消耗于数据量是相互独立的。但是这只针对page-aligned page-sized的数据，基于此，这只有面对大量数据时才有意义。

通常‘page-flipping’方案在各个内客机I/O涉及两个分离的page table改变：一个是对应，另一个取消对应。我们必须确定确保缓冲在释放前已经被取消对应，否则当一个page还在被其他客机使用时，就可能被回收作其他用处。应为完成的通知可以批量处理或者推迟，因此消耗可以被分摊。但是在SMP系统上，这种操作依然消耗很大。

永久的共享一个段固定的内存能避免 page flip，但是并不适合客机系统例如glinux的目标：因为如果我们可以从一个短固定的内存读取数据，那么其他方面也可以，因此我可以只是从其他的客机来读取。

现在很少有大量的客机间的复制， 因为TSO的实现，virtio——net被限制成64k的数据包，客机件的模块设备就是这样一个不起眼的用例。尽管如此，证明page－flipping的价值是一个简单的代码问题，而我们怀疑的结果是没有意义的的，我们希望一些发烧友能够挑战我们并以证明我们的错误。

这项工作可能永远不能完成的愿意是，即将使用的用以复制大量数据的DMA引擎。他们与page－flipping有相似的好处，大量cache－cold传输。

5. CURRENT VIRTIO DRIVERS

现在我们熟悉了linux virtio 和virqueque的概念，以及其api和一种传输的实现。参考一些现有的virtio驱动是很有价值的。因为kvm模拟出控制台，我们有一个简单笨拙的lguest控制台驱动，直到有人发布一些类似 virtcon benchmark的工具，控制台的性能才引起人们的注意。

我们还有一个ballon驱动能使主机规定他想从客机获取的page的数量。客机传入page 数的数组给主机，主机可以取消这些page的对应，并在它们被存取时把它们替换成0page。

我们将会深入的讨论两个普遍而重要的驱动，模块和网络驱动。

5.1 Virtio Block Driver

对于模块驱动，我们有一个简单的请求队列。在队列中的每个缓冲的前16字节都是只读的描述符。
struct virtio_blk_outhdr{    __u32 type;    __u32 ioprio;    __u64 sector;};
类型表示他是否是读取，写入或者通用SCSI命令，并且是否有一个写入屏障优先于这个命令。IO优先级允许客机提示请求的相对优先级。这一项被所有现有实现适当的忽略了。扇区是512字节的读取或写入的偏移量。

描述符除了一个字节外的其它字节的不是只读就是只写，这取决于请求的类型，其长度决定了请求的大小。最后一个字节是只写，表明该请求成功（0），失败（1）不支持（2）。

模块驱动支持屏障和简单的scsi命令（主要用于拔除虚拟CDROMs）对于更复杂的应用，一个在virtio上的SCSI HBA应该被安装。

5.1.1 Virtio Block Mechanics

为了更好的聚焦这个机制，我们将会用virtio——ring作为传输的例子来详述virtio模块驱动遍历来执行单一模块读取的过程。最开始，客机有一个将被读入数据的空缓冲。我们通过请求元数据来定位 struct virtio_blk_outhdr，一个字节来读取状态（成功或失败），如图2所示。

我们把请求的3部分转化成写入描述符表3步，并把它们串联起来。在这个例子中，我们读取的缓冲是物理连续的：如果不是，我们将使用多步读取描述符表。头部是只读的，空缓冲和状态字节时只写的，如图3所示。

当这一步完成，描述符	就会被标记为可用，如图4所示。这是因为把描述符头的索引放入了可用的ring，并设置一个内存障碍，然后将可用索引加一。一个kick被给出来通知主机有一个待处理请求(实际上我们的驱动江所有待处理请求放置在ring中，然后给出一个kick)。

在接下来某一时刻，请求会如图5所示完成：缓冲被填满，，状态字节更新为成功。到这时，用过的ring返回描述符头，并通知客机。模块驱动回调函数get－buf不停的查看哪些请求结束了，直到返回null。



5.2 Virtio Network Driver