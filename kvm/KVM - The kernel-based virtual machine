KVM - The kernel-based virtual machine

abstract

1960年代虚拟化的引入是因为当时计算系统还很庞大且昂贵。它允许用户通过并行运行自己的任务来共享计算资源。今年来，虚拟化又成为了一个热门话题，并出现了许多应用。

虚拟化能通过在一台主机运行多个虚拟机。这项工作主要是通过一个完整的操作系统运行在一个独立的虚拟机上来完成系统级虚拟化。一个虚拟监控器用来运行这些虚拟机，它是物理硬件与虚拟机的中间层。它的另一项职责是控制计算时间和内存管理。最近几年intel和AMD都发布了支持这一功能的硬件。

KVM是最早集成进vanilla linux内核的虚拟化工具，这篇文章将简述其历史并介绍更多的他的结构跟执行模式。

1Introduction

虚拟化不是新技术，60年代计算系统又大又昂贵。在那时，在一段时间内一个硬件只能执行一段程序。为了同时执行多个程序时间共享被引入。这种方案的一个主要问题是运行程序的隔离性。如果一个程序造成一个硬件问题，其他都将受到影响。为了隔离他们，虚拟化提供了几种隔离环境来运行他们。

70年代硬件架构开始留意虚拟化。IBM大型机允许管理员对硬件进行分区以提供隔离的环境给各个程序。

80年代，随着X86架构的流行和硬件价格的下降，在一台机器上运行一个程序成为可行的。操作系统也支持多任务所以不需要在进行时间共享。虚拟化成为历史。

最近几年虚拟化又卷土重来.Intel和AMD扩展IA32结构为X86处理器来支持虚拟化。因为他们是CPU市场的重要角色，几乎所有近期的PC和服务器都支持虚拟化。

现在，虚拟化主要被用来集群合并。有很多种类的合并，下面这些例子应该能给出一个基本概念。许多服务器在消耗许多能源下低负荷运行。服务器合并是把每个运行负荷优化服务器作为一个VM在一个虚拟主机上运行。当连接很少时，这些VM动态迁移到更少的虚拟主机并关掉其他的来减少能量消耗降低成本。如果负荷增大，更多的主机需要来满足服务器的目标，VM会再次启动，一些VM也会迁移上去。

另一个例子是程序合并，虚拟化被用来替代旧系统的旧硬件。它提供一个可以模拟运行着历史系统的旧硬件环境。
沙盒是虚拟化的另一个目标，它主要是提高在VM中运行潜在不安全程序的安全性。专家们可以观察一个跑在一个隔离环境中程序的行为。因此恶意软件和其他可以的软件能在破坏机器和入侵公司网站前被发现。

有很多种技术提供和运行VM，其中之一是VMM。这样一个VMM代表一个运行在硬件上的软件层。它运行这所有的其上运行的VM，在第二章，我们将详述这种技术，和目前的支持该技术的硬件。基于此，第三章，我们将介绍KVM--一个linux虚拟化扩展。

2 系统虚拟化

2.1 定义
虚拟化是一个确定的议题，有一些关于它的定义，以下是一个一般性的定义:
"虚拟化是一种通过硬件或者软件分割或聚合，部分或全部机器模拟仿真，时间共享等其多种手段来结合或者分离计算资源来提供一个或多个操作环境的技术。"
这意味这，虚拟化运用各种技术来抽象真正的硬件来提供隔离的环境，也就是虚拟机。他们能够运行多种程序甚至一个操作系统。一个未提到的定义是，获得几乎本地的运行性能。这是非常重要的一点，因为用户总会想尽量利用自己的硬件。如果，大量的cpu资源被管理VM所浪费的话，他们中的大多数不愿意使用虚拟技术。

同一般意义上的虚拟化一样，系统虚拟化也被很好的定义了：
"一个系统虚拟机，提供了一个包括操作系统和多个属于不同用户共存的进程的环境。"
这个完整的环境，是指一个可以提供普通硬件包括乙太网控制器，CPU，或者硬盘并包含一个操作系统运行在其上的环境。一个服务器硬件一般会跑多个VM。这样的一个服务器称为虚拟化主机，在其上运行的VM成为客机，操作系统执行在一个客机中是一个客系统。
对于本文，我们所说的虚拟化，是系统虚拟化。

2.2 虚拟机监控器
一个虚拟机监控器被称作管理程序，是一个执行在主机硬件之上的软件或硬件。它一个物理硬件与VM的一个中间层。所有客机都被VMM监控着。它提供给用户工具去管理客机，这些工具允许一些运用例如开始停止一个客机，或者在主机之间迁移。

一个VM通常有至少一个虚拟CPU，一个VMM对应其虚拟机上的虚拟CPU与主机的物理CPU。因此，比起主机上的物理内存，通常有更多个VM在该主机上运行，所以需要某种排期。因此一个VMM用某种排序机制来分配一定物理CPU到各个虚拟CPU。一个VMM也必须处理内存管理。它也把一定量的物理内存分配给VM内存地址，同时处理内存分区和内存置换。因为一些VM需要更多的内存，分配的内存量通常被管理工具动态的调整。

通常，VM不会使用物理硬件也不知道物理硬件。只有在需要直接运用，物理设备可能被直接接入。对运行旧系统这一点可能很重要。但是大多数情况下，VMM提供给不同VM虚拟I/O设备例如网卡，硬盘，和CD驱动，VMM提供不同VM几乎一样的硬件，这样更容易在不同主机上迁移。虚拟I/O设备的驱动秩序要安装一次。

2.3 硬件支持
为了安装一个VMM在一个X86构架，硬件协助是必须的。一方面权限级别的设置，使CPU限制任务的进程的执行。另一方面，VMM对仿真的内存管理不够高效。硬件支持能够增加VMM支持的vm的性能。

2.3.1 权限级别
大多数现代操作系统不允许程序执行一些操作。只有OS可以读取驱动或者直接接入硬件。为了限制所有运行的程序在一个子资源中，OS 和CPU合力用于权限级别。一个X86 cpu在任意时间运行在一个特定的运行节别。图2展示了一个级别环。0环拥有最高权限而3环则是最低权限。被权限级别保护的资源有：内存，I/O接口和cpu指令。操作系统一般在0环运行。它需要最高的权限去进行资源管理来提供硬件接入。其他所有程序都运行在3环。1环2环通常闲置。从os的角度来说，0环是内核模式，3环是用户模式。

已经在2.2提到，VMM需要运用主机内存，cpu，I/O设别。因为只有在0环运行的代码可以执行这些操作，它需要与内核一起运行在最高等级的权限中。一个安装在vm中的操作系统同样需要向VMM运行在0环一样去使用所有资源。实际上在同一时间只有一个内核可以运行在0环，客机的OS则运行在另外一个较低的级别或者被修改运行在用户模式。

Intel 和AMD 意识到这是X86架构下虚拟化的重大挑战。所以他们引入了Intel VT 和 AMD SVM 作为一个对 IA-32架构的扩展来更好的支持虚拟化。这些扩展允许VMM在一个较低的权限级别下运行内核模式的客机OS。

2.3.2 内存管理
为了在一个服务器上运行多个VM，需要拥有多个内存的服务器。因为一个VM运行这个一整个操作系统及其应用，所以推荐在物理机器上分配尽量多的内存给VM。VMM分割主机的物理内存成连续的定长的区块，分配到VM提供的地址空间。

多数现代操作系统都使用虚拟内存管理。这项技术允许提供之前提到的连续区块的内存给一个VM，尽管它分割任意的物理内存甚至部分存储在硬盘。这种情况下，当使用时它需要通过虚拟内存管理读取数据。因为VM不知晓物理内存的的内存空间，它不知道部分的虚拟内存是否需要被读取。为了达到这一目标，VMM用shadow page table 存储所有VM的虚拟内存的物理地址。所以，任意时间一个VM写入他的内存，这一操作需要被打断保证 shadow pages 的更新。当一个置换地址被VM使用，VM运用虚拟内存管理来获取它。随着INTEL EPT 和AMD NPT的引入，一个VMM可以使用硬件支持来转化虚拟和物理内存。这减少了保存shadow pages的消耗提高了VMM的性能。

2.4 虚拟化技术
随着问题和解决方案在之前章节的提出，我们现在来看以下两个技术来实现系统虚拟化。
 
2.4.1 准虚拟化

准虚拟化方案允许各个客机运行一个操作系统，但是都不能运行在0环。这是由于所有高权限的指令不能被客机执行。为了如此
，客机操作系统需要添加一个接口。它将被VMM运用来取得VM的控制和处理受限制的指令。准虚拟化方案几乎达到了本地化的性能，但是缺乏对非开源系统的支持。为了运用之前提到的修改，系统内核的源代码需要被修补，因此使用准虚拟化在一个VM上运行微软的windos是不可行的。

2.4.2 全虚拟化

这个方案允许在一个主系统上运行多个操作系统。每个系统运行在各自隔离的VM。VMM用硬件支持来并不需要修改来运行这些客机系统。VMM提供I/O 设备给各个模拟旧硬件的VM。这确保一个客机os有驱动支持这些设备。因为这些模拟的部分，全虚拟化没有准虚拟化那么快。但是可以运行非开源的os，也是唯一可行的方案。

3 KVM - 基于内核的虚拟机

KVM最初由一个以色列的小公司Qumranet开发，当KVM更加适用于生产环境后，红帽于2008年9月收购了Qumranet。他们视KVM下一代虚拟化技术。现在，自5.4版本后它被用作RHEL和EEVS中的基础VMM。

Qumranet在开源社区发布了KVM的代码。现在，许多知名公司如IBM， Intel和AMD也也是这个项目的贡献者之一。从2.6，20版后，KVM 成为了vanilla linux 内核的一部分，因此可用于所有用新内核的基于linux的操作系统中。更重要的是，它受益与世界级对开源系统的开发，当linux通过新算法，驱动或其他获得更好的性能，KVM也同样获得更好的性能。

KVM 是一个运用全虚拟化技术的系统虚拟化解决方案。它有较小的代码量，因为它被设计来运用在2.3中介绍的支持化的硬件。KVM主要在X86架构上运行，但是IA64 和IBM s390最近也支持了KVM。

3.1 架构

3.1.1 linux as a VMM
linux有一个VMM需要的全部机能来运行多个VM。我们已经在2.2提到这些技能。所以开发者并没有从新造轮子而是增加了一些部件来支持虚拟化。KVM被开发为一个内核的模块并能读取扩展linux，因此，linux成为了一个VMM。

在普通的linux环境中，每个进程不是在用户模式下执行就是在内核模式下执行。KVM引入了第三种模式，客人模式。因此 它依赖一个能够支持虚拟化的拥有Intel VT 或者AMD SVM扩展的CPU。一个进程在客人模式下有自己的内核模式和用户模式。因此它能运行一个操作系统。这些进程代表了运行在KVM主机上的VM。Qum06的作者从主机的角度陈述了与用了哪些模块：
用户模式： I/O 当客机需要运用设备。
内核模式： 切换客人模式并处理I/O操作的返回。
客人模式： 执行客机上的OS代码，除了I/O操作。

3.1.2 资源管理
KVM 开发者目标重利用尽量多的代码。基于此他们主要修改了linux的内存管理来对照物理内存到VM地址空间。因此他们在Intel 和AMD 为未引入EPT 和 NPT之前，增加了最早在X86上需要的shadow page tables。到了2008年5月这些技术的者支持被引入。

在现代操作系统中，有更多的进程在CPU运行。一个操作系统的排期器计算着被分配给CPU的进程的序列。这样，所有运行的进程共享计算时间。因为KVM开发者向重利用linux的大部分机能。他们开发了VM作为一个进程，依靠排期器来分配计算资源给VM。

3.1.3 KVM 控制接口
一但KVM内核模块被加载，/dev/kvm设备会出现在文件系统中。这个特殊的设备代表着KVM的接口。它允许通过一些列ioctls来控制管理程序。这些通称作为接口被用在一些操作系统中，使进程在用户模式中与驱动通信。ioctl系统调用允许执行多个操作来建立新VM，分配内存到一个VM，分配停止虚拟CPU。

3.1.4 模拟硬件
为了提供硬件，例如硬盘，cd 驱动 或者网卡 给VM，KVM 用了高度修改过的QEMU。这成为平台虚拟化工具，用来模拟一个完整的包括图形，网络，硬盘等的PC平台。对于每个VM一个QEMU进程被启动成用户模式并且一些模拟设备被虚拟的与之相连。当一个VM执行I/O操作，这些被KVM打断然后重定向至QEMU进程给客机。

3.2 执行模式
图4描绘了KVM的执行模式。这个循环动作被原来运行VM。这些动作被区分为前述3.1.1三个模式.

Kivity 等人描述了KVM执行模式，并描述那些任务在那些模式下执行：
用户模式： KVM模块被ioclt调用来执行客机代码，直到I/O操作发生或者外部时间发生。这样的一个时间可以是一个网络包的到达，需要以来主机发送网络包。这样的事件被称为中断客机代买执行的信号。
内核模式：内核引起硬件执行客机本地代码。如果由于等待内存或I/O操作，一个进程退出客机，内核执行必要的任务来继续执行流程。如果一个外部时间例如 信号 或者I/O操作被客机退出触发，它退出至用户模式。
客人模式：这是在硬件层，虚拟化支持的CPU被用来执行本地代码，直到需要KVM协助的一条指令被调用，一个错误或者外部中断。

当一个VM运行，有很多模式间的切换。从内核模式到客人模式之前的切换很快，反之已然。因为期间之后很少的本地代码被底层硬件执行。当I/O操作发生，执行流切换至用户模式，模拟虚拟I/O设备起了作用。因此，大量I/O返回和切换到用户模式。可以设想一个模拟硬盘和客机从中读取一段信息。然后QEMU通过模拟硬盘的行为和连接的控制器来模拟这些操作。为了执行客机读取操作，它读文件种读取对应的信息然后返回数据给客机。因此用户模式模拟的I/O往往成为一个使VM执行变慢的瓶颈。

3.3 准虚拟设备驱动

随着对virtio 准虚拟化设备模式的支持，KVM强调了运用QEMU模式设备造成的性能限制。Virtio是一个常用框架 来开发VMM独立驱动来实现裸机速度。自此，准模拟设别连接到VM不再需要模拟。

作为替代，一个准虚拟驱动后端被用来直接执行I/O操作或者通过用户模式。KVM运用QEMU作为一个后端来直接处理I/O程序。因此，通过运用内核驱动来执行特定操作，相应来模拟一个IDE硬盘的消耗被大大减少。

4 Conclusion
虚拟化能被大量和广泛的程序。自从CPU制造商引入各种技术来构建更加高效的VMM，VMM能被运行在广泛流行的X86架构上。KVM是能够利用CPU来通过系统细腻化来执行VM一个开源的虚拟化解决方案。它允许在一个主机上的多个隔离的虚拟机上运行多个操作系统。KVM被设计成一个内核模块，当它被载入，linux成为一个VMM。因为开发正不想重新造轮子，KVM依赖内核的机制来安排计算子阮，并从大量驱动支持中获益。内存管理被扩展成能够管理分配给一个VM的地址空间。

因为提供给VM的模拟驱动性能并不好，KVM支持了virtio设备模式。因为准虚拟化驱动可以忽略某些设备，它极大的增强的I/O性能。

